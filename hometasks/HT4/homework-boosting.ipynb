{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Практическое задание 4. Бустинг и бэггинг\n",
    "\n",
    "## Общая информация\n",
    "Дата выдачи: 14.01.2024\n",
    "\n",
    "Мягкий дедлайн: 28.01.2024 23:59 MSK\n",
    "\n",
    "Жёсткий дедлайн: 04.02.2024 23:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. \n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-04-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия на латинице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О задании\n",
    "\n",
    "В этом задании вам предстоит вручную запрограммировать один из самых мощных алгоритмов машинного обучения — бустинг. Работать мы будем на двух наборах данных: многомерных данных по кредитам с kaggle и синтетических двумерных. В данных с kaggle целевая переменная показывает, вернуло ли кредит физическое лицо:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, f1_score, log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget  -O 'bank_data.csv' -q 'https://www.dropbox.com/s/uy27mctxo0gbuof/bank_data.csv?dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>54</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>32</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>41</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.354</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>mar</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.843</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.602</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age           job   marital    education  default housing loan  \\\n",
       "7449   54     housemaid  divorced     basic.4y       no     yes  yes   \n",
       "7270   32        admin.   married  high.school       no     yes  yes   \n",
       "1710   41  entrepreneur   married  high.school  unknown      no   no   \n",
       "7038   33      services   married  high.school       no      no  yes   \n",
       "4584   33   blue-collar    single  high.school       no     yes   no   \n",
       "\n",
       "        contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "7449   cellular   jul         mon  ...         3    999         0   \n",
       "7270   cellular   apr         fri  ...         1    999         1   \n",
       "1710  telephone   may         thu  ...        13    999         0   \n",
       "7038   cellular   may         mon  ...         2    999         1   \n",
       "4584   cellular   mar         wed  ...         4    999         1   \n",
       "\n",
       "         poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "7449  nonexistent          1.4          93.918          -42.7      4.962   \n",
       "7270      failure         -1.8          93.075          -47.1      1.405   \n",
       "1710  nonexistent          1.1          93.994          -36.4      4.860   \n",
       "7038      failure         -1.8          92.893          -46.2      1.354   \n",
       "4584      failure         -1.8          92.843          -50.0      1.602   \n",
       "\n",
       "      nr.employed  y  \n",
       "7449       5228.1 -1  \n",
       "7270       5099.1 -1  \n",
       "1710       5191.0 -1  \n",
       "7038       5099.1 -1  \n",
       "4584       5099.1  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank_data.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на train и test (random_state не меняем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем синтетические данные (seed не меняем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_obs = 10 ** 5\n",
    "num_thresholds = 50\n",
    "\n",
    "X_synthetic = np.random.normal(scale=3, size=[num_obs, 2])\n",
    "x1_thresholds = np.random.choice(X_synthetic[:, 0], num_thresholds, False)\n",
    "x2_thresholds = np.random.choice(X_synthetic[:, 1], num_thresholds, False)\n",
    "\n",
    "gains = np.random.uniform(-0.4086, 0.5, size=[2 * num_thresholds, 1])\n",
    "x1_thresholds_cond = [X_synthetic[:, 0] >= threshold for threshold in x1_thresholds]\n",
    "x2_thresholds_cond = [X_synthetic[:, 1] >= threshold for threshold in x2_thresholds]\n",
    "\n",
    "noise = np.random.uniform(-0.5, 0.5, size=num_obs)\n",
    "\n",
    "y_synthetic_probits = np.sum(\n",
    "    gains[:num_thresholds] * x1_thresholds_cond + gains[num_thresholds:] * x2_thresholds_cond, axis=0\n",
    ") + noise\n",
    "y_synthetic = np.sign(y_synthetic_probits)\n",
    "\n",
    "X_train_synthetic, y_train_synthetic = X_synthetic[:int(num_obs * 0.8)], y_synthetic[:int(num_obs * 0.8)]\n",
    "X_test_synthetic, y_test_synthetic = X_synthetic[int(num_obs * 0.8):], y_synthetic[int(num_obs * 0.8):]\n",
    "\n",
    "px.histogram(x = y_synthetic_probits, nbins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторый полезный код для визуализации предсказаний (пригодится позже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predicts(model, features, targets, x_lim=[-15.0, 15.0], y_lim=[-15.0, 15.0],\n",
    "                  examples_density=0.01, steps=1000, num_ticks=6, title='', mode='classification'):\n",
    "    '''\n",
    "    Функция для визуализации предсказаний модели на двухмерной плоскости\n",
    "    param model: обученная модель классификации или регрессии для двухмерных объектов\n",
    "    param features: признаки выборки (a.k.a. X)\n",
    "    param targets: целевая переменная выборки (a.k.a y)\n",
    "    param x_lim: пределы для x\n",
    "    param y_lim: пределы для y\n",
    "    param examples_density: доля выборки, которая будет нарисована\n",
    "    param steps: частота разбиения плоскости\n",
    "    param num_ticks: число подписей на графике\n",
    "    param title: заголовок графика\n",
    "    param mode: режим 'classification' - вероятности положительного класса\n",
    "                режим 'regression' - вещественная целевая переменная\n",
    "    '''\n",
    "    \n",
    "    mask = np.random.choice([True, False], size=features.shape[0], \n",
    "                            p=[examples_density, 1.0 - examples_density])\n",
    "    features_x = (features[mask, 0] - x_lim[0]) / (x_lim[1] - x_lim[0]) * steps\n",
    "    features_y = (features[mask, 1] - y_lim[0]) / (y_lim[1] - y_lim[0]) * steps\n",
    "    \n",
    "    xs = np.linspace(x_lim[0], x_lim[1], steps)\n",
    "    ys = np.linspace(y_lim[0], y_lim[1], steps)\n",
    "    \n",
    "    xs, ys = np.meshgrid(xs, ys)\n",
    "    grid = np.stack([xs.flatten(), ys.flatten()], axis=1)\n",
    "    if mode == 'classification':\n",
    "        predicts = model.predict_proba(grid)[:, 1].reshape(steps, steps)\n",
    "        values = (targets[mask] == 1).astype(np.float)\n",
    "    elif mode == 'regression':\n",
    "        predicts = model.predict(grid).reshape(steps, steps)\n",
    "        values = targets[mask]\n",
    "    else:\n",
    "        raise ValueError('Unknown mode')\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(predicts, origin='lower')\n",
    "    plt.scatter(features_x, features_y, c=values, edgecolors='white', linewidths=1.5)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.xticks(np.linspace(0, steps, num_ticks), np.linspace(x_lim[0], x_lim[1], num_ticks))\n",
    "    plt.yticks(np.linspace(0, steps, num_ticks), np.linspace(y_lim[0], y_lim[1], num_ticks))\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (4 балла) Реализуйте бустинг для задачи бинарной классификации.\n",
    "\n",
    "Поскольку градиентный бустинг обучается через последовательное создание моделей, может получиться так, что оптимальная с точки зрения генерализации модель будет получена на промежуточной итерации. Обычно для контроля такого поведения в методе `fit` передается также валидационная выборка, по которой можно оценивать общее качество модели в процессе обучения (желательно делать это каждую итерацию, но если ваша имплементация слишком медленная или ваше железо не тянет, можно делать это реже). Кроме того, нет смысла обучать действительно глубокую модель на 1000 деревьев и больше, если оптимальный ансамбль получился, к примеру, на 70 итерации и в течение какого-то количества итераций не улучшился - поэтому мы также задействуем early stopping при отсутствии улучшений в течение некоторого числа итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boosting:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model_class=DecisionTreeRegressor,\n",
    "        base_model_params: dict={'max_features': 0.1},\n",
    "        n_estimators: int=10,\n",
    "        learning_rate: float=0.1,\n",
    "        subsample: float=0.3,\n",
    "        random_seed: int=228,\n",
    "        custom_loss: list or tuple=None,\n",
    "        use_best_model: bool=False,\n",
    "        n_iter_early_stopping: int=None\n",
    "    ):\n",
    "        \n",
    "        # Класс базовой модели\n",
    "        self.base_model_class = base_model_class\n",
    "        # Параметры для инициализации базовой модели\n",
    "        self.base_model_params = base_model_params\n",
    "        # Число базовых моделей\n",
    "        self.n_estimators = n_estimators\n",
    "        # Длина шага (которая в лекциях обозначалась через eta)\n",
    "        self.learning_rate = learning_rate\n",
    "        # Доля объектов, на которых обучается каждая базовая модель\n",
    "        self.subsample = subsample\n",
    "        # seed для бутстрапа, если хотим воспроизводимость модели\n",
    "        self.random_seed = random_seed\n",
    "        # Использовать ли при вызове predict и predict_proba лучшее\n",
    "        # с точки зрения валидационной выборки число деревьев в композиции\n",
    "        self.use_best_model = use_best_model\n",
    "        # число итераций, после которых при отсутствии улучшений на валидационной выборке обучение завершается\n",
    "        self.n_iter_early_stopping = n_iter_early_stopping\n",
    "        \n",
    "        # Плейсхолдер для нулевой модели\n",
    "        self.initial_model_pred = None\n",
    "        \n",
    "        # Список для хранения весов при моделях\n",
    "        self.gammas = []\n",
    "        \n",
    "        # Создаем список базовых моделей\n",
    "        self.models = [self.base_model_class(**self.base_model_params) for _ in range(self.n_estimators)]\n",
    "        \n",
    "        # Если используем свою функцию потерь, ее нужно передать как список из loss-a и его производной\n",
    "        if custom_loss is not None:\n",
    "            self.loss_fn, self.loss_derivative = custom_loss\n",
    "        else:\n",
    "            self.sigmoid = lambda z: 1 / (1 + np.exp(-z))\n",
    "            self.loss_fn = lambda y, z: -np.log(self.sigmoid(y * z)).mean()\n",
    "            self.loss_derivative = lambda y, z: -y * self.sigmoid(-y * z)\n",
    "        \n",
    "        \n",
    "    def _fit_new_model(self, X: np.ndarray, y: np.ndarray or list, n_model: int):\n",
    "        \"\"\"\n",
    "        Функция для обучения одной базовой модели бустинга\n",
    "        :param X: матрица признаков\n",
    "        :param y: вектор целевой переменной\n",
    "        :param n_model: номер модели, которую хотим обучить\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your code is here ╰( ͡° ͜ʖ ͡° )つ──☆*:\n",
    "        \n",
    "        \n",
    "    def _fit_initial_model(self, X, y):\n",
    "        \"\"\"\n",
    "        Функция для построения нулевой (простой) модели. Не забудьте взять логарифм, потому что сигмоида применяется\n",
    "        уже к сумме предсказаний базовых моделей, а не к каждому предсказанию каждой модели по отдельности.\n",
    "        Подойдёт константная модель, возвращающая самый популярный класс,\n",
    "        но если хотите, можете сделать что-нибудь посложнее.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:\n",
    "    \n",
    "    \n",
    "    def _find_optimal_gamma(self, y: np.ndarray or list, old_predictions: np.ndarray,\n",
    "                            new_predictions: np.ndarray, boundaries: tuple or list=(0.01, 1)):\n",
    "        \"\"\"\n",
    "        Функция для поиска оптимального значения параметра gamma (коэффициент перед новой базовой моделью).\n",
    "        :param y: вектор целевой переменной\n",
    "        :param old_predictions: вектор суммы предсказаний предыдущих моделей (до сигмоиды)\n",
    "        :param new_predictions: вектор суммы предсказаний новой модели (после сигмоиды)\n",
    "        :param boudnaries: в каком диапазоне искать оптимальное значение ɣ (array-like объект из левой и правой границ)\n",
    "        \"\"\"\n",
    "        # Определеяем начальные лосс и оптимальную гамму\n",
    "        loss, optimal_gamma = self.loss_fn(y, old_predictions), 0\n",
    "        # Множество, на котором будем искать оптимальное значение гаммы\n",
    "        gammas = np.linspace(*boundaries, 100)\n",
    "        # Простым перебором ищем оптимальное значение\n",
    "        for gamma in gammas:\n",
    "            predictions = old_predictions + gamma * new_predictions\n",
    "            gamma_loss = self.loss_fn(y, predictions)\n",
    "            if gamma_loss < loss:\n",
    "                optimal_gamma = gamma\n",
    "                loss = gamma_loss\n",
    "        \n",
    "        return optimal_gamma\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, eval_set=None):\n",
    "        \"\"\"\n",
    "        Функция для обучения всей модели бустинга\n",
    "        :param X: матрица признаков\n",
    "        :param y: вектор целевой переменной\n",
    "        :eval_set: кортеж (X_val, y_val) для контроля процесса обучения или None, если контроль не используется\n",
    "        \"\"\"\n",
    "            \n",
    "        # Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:\n",
    "        \n",
    "        \n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Функция для предсказания классов обученной моделью бустинга\n",
    "        :param X: матрица признаков\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:\n",
    "        \n",
    "    def predict_proba(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Функция для предсказания вероятностей классов обученной моделью бустинга\n",
    "        :param X: матрица признаков\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:\n",
    "        \n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        \"\"\"\n",
    "        Для бонусного задания номер 5.\n",
    "        Функция для вычисления важностей признаков.\n",
    "        Вычисление должно проводиться после обучения модели\n",
    "        и быть доступно атрибутом класса. \n",
    "        \"\"\"\n",
    "        # Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тест для вашей имплементации. Если класс написан правильно, две следующие ячейки должна отработать без ошибок и относительно быстро (у автора задания 2 и 0.2 секунд соответственно, accuracy 0.911 и 0.879 соответственно). Если у вас получилось качество выше указанного — отлично!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "boosting = Boosting()\n",
    "boosting.fit(X_train_synthetic, y_train_synthetic)\n",
    "# Без разницы, выдает эта строка классы или вероятности\n",
    "preds = np.round(boosting.predict(X_test_synthetic) > 0.5)\n",
    "assert accuracy_score((y_test_synthetic == 1), np.round(preds)) > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "boosting = Boosting()\n",
    "boosting.fit(df_train.select_dtypes(['int64', 'float64']).drop(columns='y').values, df_train.y.values)\n",
    "# Без разницы, выдает эта строка классы или вероятности\n",
    "preds = np.round(boosting.predict(df_test.select_dtypes(['int64', 'float64']).drop(columns='y').values) > 0.5)\n",
    "assert accuracy_score((df_test.y.values == 1), np.round(preds)) > 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (2 балла) Сравните результаты вашей имплементации бустинга с указанными ниже базовыми моделями на обоих датасетах и ответьте на вопросы. Разумеется, надо измерять качество на тестовых данных. \n",
    "\n",
    "Варианты для базовой модели (разумеется, не надо их программировать самостоятельно, берите нужные классы из sklearn):\n",
    "\n",
    "- Решающее дерево глубины 6\n",
    "- Случайный лес (число деревьев — на ваше усмотрение, только не слишком мало)\n",
    "- Линейная регрессия\n",
    "\n",
    "Вопросы:\n",
    "\n",
    "1) Какая из моделей имеет оптимальное качество? С чем это связано?\n",
    "\n",
    "2) Какая из моделей сильнее переобучается? Есть ли преимущества от использования ранней остановки и обрезания бустинга до лучшей модели?\n",
    "\n",
    "3) Работает ли бустинг над линейными регрессиями лучше, чем одна логистическая регрессия? Как объяснить этот результат?\n",
    "\n",
    "4) Визуализируйте предсказания моделей на синтетическом датасете (для этого можете воспользоваться вспомогательной функцией plot_predicts). Чем отличаются картинки, которые получаются у разных алгоритмов? Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (2 балла) Мы разобрались с бустингом, теперь интересно посмотреть на совсем дикие комбинации моделей. Сравните результаты следующих моделей на обоих датасетах и ответьте на вопросы. Разумеется, надо измерять качество на тестовых данных.\n",
    "\n",
    "Используйте логистическую регрессию, случайный лес и BaggingClassifier из sklearn.\n",
    "\n",
    "- Случайный лес\n",
    "- Бэггинг на деревьях (поставьте для базовых деревьев min_samples_leaf=1)\n",
    "- Бэггинг на деревьях с обучением каждого дерева на подмножестве признаков (`max_features` около 0.6 в BaggingClassifier)\n",
    "- Бэггинг, у которого базовой моделью является бустинг с большим числом деревьев (> 100)\n",
    "- Бэггинг на логистических регрессиях\n",
    "\n",
    "1) Какая из моделей имеет лучшее качество? С чем это связано?\n",
    "\n",
    "2) Какая из моделей сильнее всего переобучается? Помогает ли бустингу ранняя остановка? \n",
    "\n",
    "3) Исправляет ли бэггинг переобученность бустинга с большим числом деревьев?\n",
    "\n",
    "4) Что лучше: случайный лес или бэггинг на деревьях с сэмплированием признаков?\n",
    "\n",
    "5) Если использовать деревья в качестве базового алгоритма, что лучше — бэггинг или бустинг? С чем это связано?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (2 балла) Сравните на этих данных любую из трёх популярных имплементаций градиентного бустинга (xgboost, lightgbm, catboost) с вашей реализацией. Подберите основные гиперпараметры (число деревьев, длина шага, глубина дерева/число листьев) для обоих методов. Получилось ли у вас победить библиотечные реализации на тестовых данных? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "210px",
    "width": "492px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
